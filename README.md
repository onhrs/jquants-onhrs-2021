# J-Quants
J-Quantsの参加した時のコードになります。


ファンダメンタルズ分析チャレンジとニュース分析チャレンジの両方に参加し、ニュース分析チャレンジで9位入賞いたしました。




</br>
</br>

# 構成

```
.
├── api # チュートリアルのapiから取得のコード
│   ├── __init__.py
│   └── fetch_api.py
│
├── data #読み込むデータ。gitignoreしています。
│　　└── ....
│
├── backtest # チュートリアルのバックテストのコード
│   └── backtest.py
│
│
├── learner #学習のパフォーマンスを調べる際に使用
│   └── preprocessors.py
│
├── notebooks
│   └── API
│   │   ├── api_取得.ipynb
│   │   └── api_取得_news.ipynb
│   │
│   ├── 1.財務諸表で株価の先行きを予測しよう_モデル作成.ipynb
│   ├── 2.最終動作確認.ipynb
│   └...
│
└── predict #推論コード
    ├── __init__.py
    ├── model
       　└── ....
    ├── requirements.txt
    └── src
        ├── __init__.py
        ├── config.py
        ├── fundamental #ファンダメンタル分析での推論コード
        │   └── predictor.py
        ├── module.py
        ├── pipeline.py　#パイプライン化したコード
        └── predictor.py # ニュース分析での推論コード

```

# 戦略

チュートリアルをベースにテクニカルインジケーターを追加（rsi/macd/atrなど）、lag特徴量の追加に加え。UKIさんのノートブックを参考にprofit marginなどを追加しました。
その他APIでのデータを取得、直近までのデータを学習。予測精度の悪い区間の削除。2020年を4半期で分けて評価、直近のデータを意図的に増やすなどしてみました。

推論と学習を差異が無いようにpipeline化など、実装の工夫をしましたが、残念ながら、直近のコードの学習する際、API側の欠損の対応としてdropnaの処理をしたことがリークの対象になってしまい、ファンダメンタルズ分析では失格となってしましました。

ニュース分析では、上記で生成したモデルを修正、転用し、ポートフォリオの分散する銘柄数をできるだけ大きくし、個々の銘柄の金額を低く調整しました。参加者のほぼ全ての方がマイナスの結果となる波乱の相場の中において、プラスの値を示せたので、有効な戦略であったと考えました。

ニュースデータについて、直近のデータまでを学習データとして使用し、bert+lstmのセンチメントスコアに応じてチュートリアルにあったget_cash_ratio関数のリスク許容度に応じた分散方法ではなく、全体の銘柄の所有金額を調整する方法に修正しましたが、分散する銘柄数をあげたかった考えから、デフォルトの状態でも100万円を常に超えてしまう分散方法のため、うまく作動しなかったと考えられます。

今回購入金額を下げすぎると購入できない銘柄を多くなってしまうことも、できるだけ避けたかったのでこのような実装にしまいましたが、保持現金が100万ではなく、より大きい金額だと、複雑なポートフォーリオ構築方法が可能であると考えました。

転移学習なども考えましたが、ニュース分析のコンペでは、チュートリアルがより膨大になったにもかかわらず、１ヶ月と時間の制約と、複雑なことをやろうとすると失格のファクターが増えてしまうという考えの元、チュートリアルベースで進めました。ですが、文脈を理解できる可能性の秘めたbertは今後のアルゴリズムトレードにおいても、間違いなく有用な指標になると考えましたので、引き続き調査して行きたいと考えました。

</br>
</br>

# 総評

ニュース分析はファンダメンタル分析と比べ運要素が大きかったでしたが、チュートリアルを勉強した上、自身で仮説を立て検証、実装を行い、それが結果に繋がったことは自身にとって、大変良い経験になりました。

最後に、全体を通して難易度の高いコンペティションでしたが、このような素晴らしいコンペを主催していただけました株式会社日本取引所グループ、世界トップの金融マーケット分析手法を惜しげもなく公開していただけたAlpacaJapan株式会社、データセットを提供していただけた株式会社日本経済新聞社、株式会社QUICK、オンラインの環境を用意してくれた株式会社SIGNATEには深く感謝申し上げます。
